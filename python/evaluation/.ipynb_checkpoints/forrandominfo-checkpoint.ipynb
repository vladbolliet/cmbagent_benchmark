{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c458e952-6611-42c5-a0ed-68284865c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import run_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b0da38-00c3-4cf1-8f38-5c5acd545b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================\n",
      "\t\tEvaluating CMBAgent on problem 1/4: 0001_easy_addition\n",
      "===============================================================\n",
      "Task:\n",
      "Write a function to solve the problem: Given two integers A and B, output their sum.\n",
      "\n",
      "Requirements:\n",
      "- The main function must be named `main_function`, even if helper functions are needed.\n",
      "- Include all code inside a single <code> ... </code> block, even if you revise it.\n",
      "- No extra text or explanation, only the code block.\n",
      "- Execution time must stay under 4 seconds, even for large inputs.\n",
      "\n",
      "Format:\n",
      "- Input example: [1, 2]\n",
      "- Expected output: [3]\n",
      "- Output must be a Python list:\n",
      "  - Return [n] for a single integer result.\n",
      "  - Return [a, b, c, ...] for a list result.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Calling researcher...\n",
      "\u001b[0m\n",
      "                   Model      agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "claude-3-7-sonnet-latest researcher 0.00000            637                268           905\n",
      "# Analysis of the Sum Problem\n",
      "\n",
      "The task requires implementing a function that calculates the sum of two integers and returns the result in a specific format. This is a straightforward arithmetic operation with specific input and output requirements.\n",
      "\n",
      "## Problem Requirements\n",
      "\n",
      "1. Create a function named `main_function` that takes two integers as input\n",
      "2. Calculate their sum\n",
      "3. Return the result as a single-element list\n",
      "4. Ensure execution time remains under 4 seconds even for large inputs\n",
      "\n",
      "## Solution Approach\n",
      "\n",
      "The solution is straightforward as integer addition in Python is highly optimized and can handle arbitrarily large integers efficiently. The function will:\n",
      "\n",
      "1. Accept the input parameters A and B\n",
      "2. Calculate their sum\n",
      "3. Return the result as a list containing a single element\n",
      "\n",
      "## Implementation\n",
      "\n",
      "<code>\n",
      "def main_function(A, B):\n",
      "    return [A + B]\n",
      "</code>\n",
      "\n",
      "This implementation directly addresses the requirements:\n",
      "- It uses the required function name `main_function`\n",
      "- It performs the addition operation\n",
      "- It returns the result in the specified format (a list containing the sum)\n",
      "- Addition in Python is O(1) for small integers and scales efficiently for large integers, ensuring the execution time constraint is met\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/p/stage/cmbagent_benchmark/cmbagent_env/lib/python3.12/site-packages/autogen/oai/anthropic.py:712: UserWarning: Cost calculation not available for model claude-3-7-sonnet-latest\n",
      "  warnings.warn(f\"Cost calculation not available for model {model}\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting...\n",
      "\n",
      "             Model                         agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "o3-mini-2025-01-31 researcher_response_formatter 0.00359            553                677          1230\n",
      "**Markdown:**\n",
      "\n",
      "```markdown\n",
      "<!-- filename: sum_problem_notes.md -->\n",
      "# Analysis of the Sum Problem\n",
      "\n",
      "The task requires implementing a function that calculates the sum of two integers and returns the result in a specific format. This is a straightforward arithmetic operation with specific input and output requirements.\n",
      "\n",
      "## Problem Requirements\n",
      "\n",
      "1. Create a function named `main_function` that takes two integers as input\n",
      "2. Calculate their sum\n",
      "3. Return the result as a single-element list\n",
      "4. Ensure execution time remains under 4 seconds even for large inputs\n",
      "\n",
      "## Solution Approach\n",
      "\n",
      "The solution is straightforward as integer addition in Python is highly optimized and can handle arbitrarily large integers efficiently. The function will:\n",
      "\n",
      "1. Accept the input parameters A and B\n",
      "2. Calculate their sum\n",
      "3. Return the result as a list containing a single element\n",
      "\n",
      "## Implementation\n",
      "\n",
      "<code>\n",
      "def main_function(A, B):\n",
      "    return [A + B]\n",
      "</code>\n",
      "\n",
      "This implementation directly addresses the requirements:\n",
      "- It uses the required function name `main_function`\n",
      "- It performs the addition operation\n",
      "- It returns the result in the specified format (a list containing the sum)\n",
      "- Addition in Python is O(1) for small integers and scales efficiently for large integers, ensuring the execution time constraint is met\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Saving report...\n",
      "\n",
      "Execution results:\n",
      "\n",
      "Execution output: Content saved to /mnt/p/stage/cmbagent_benchmark/python/evaluation/cmbagent_output/sum_problem_notes.md\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Calling control...\n",
      "\u001b[0m\n",
      "             Model   agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "gpt-4.1-2025-04-14 control 0.00300           1345                 39          1384\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "**Step number:** 1 out of 1.\n",
      " \n",
      "**Sub-task:** solve the main task.\n",
      " \n",
      "**Agent in charge of sub-task:** `researcher`\n",
      " \n",
      "**Instructions:**\n",
      " \n",
      "solve the main task.\n",
      " \n",
      "**Status:** completed ✅\n",
      "        \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Terminating...\n",
      "\n",
      "             Model      agent    Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "gpt-4.1-2025-04-14 terminator 0.00176            876                  1           877\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Session terminated.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Displaying cost…\n",
      "\n",
      "| Agent                         | Cost ($)    | Prompt Tokens | Completion Tokens | Total Tokens |\n",
      "|:------------------------------|------------:|--------------:|------------------:|-------------:|\n",
      "| control                       | $0.00300200 |          1345 |                39 |         1384 |\n",
      "| researcher                    | $0.00000000 |           637 |               268 |          905 |\n",
      "| researcher response formatter | $0.00358710 |           553 |               677 |         1230 |\n",
      "| terminator                    | $0.00176000 |           876 |                 1 |          877 |\n",
      "|-------------------------------|-------------|---------------|-------------------|--------------|\n",
      "| Total                         | $0.00834910 |          3411 |               985 |         4396 |\n",
      "\n",
      "Cost report data saved to: /mnt/p/stage/cmbagent_benchmark/python/evaluation/cmbagent_output/cost_report_20250620_210800.json\n",
      "\n",
      "\n",
      "Timing report saved to /mnt/p/stage/cmbagent_benchmark/python/evaluation/cmbagent_output/timing_report_20250620_210800.json\n",
      "\n",
      "Task took 29.6786 seconds\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m info = \u001b[43mrun_benchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproblem_json\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/mnt/p/stage/cmbagent_benchmark/data/clean/easy_custom_samples.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproblem_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/mnt/p/stage/cmbagent_benchmark/data/clean/easy_tests\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_cmbagent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcmbagent_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclaude-3-7-sonnet-latest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/p/stage/cmbagent_benchmark/python/evaluation/evaluation.py:578\u001b[39m, in \u001b[36mrun_benchmark\u001b[39m\u001b[34m(problem_json, problem_dir, eval_cmbagent, cmbagent_model, eval_normal_llm, llm_model)\u001b[39m\n\u001b[32m    575\u001b[39m \u001b[38;5;66;03m# evaluate cmbagent on problems\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_cmbagent: \n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m     resultscmb = \u001b[43mrun_benchmark_on_cmbagent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmbagent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresearcher\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m     print_cmbagent_benchmark_summary(resultscmb)\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# evaluate the normal LLM on problems\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/p/stage/cmbagent_benchmark/python/evaluation/evaluation.py:390\u001b[39m, in \u001b[36mrun_benchmark_on_cmbagent\u001b[39m\u001b[34m(problems, problem_dir, cmbagent_model, agent)\u001b[39m\n\u001b[32m    382\u001b[39m model_answer = cmbagent.one_shot(\n\u001b[32m    383\u001b[39m     prompt,\n\u001b[32m    384\u001b[39m     max_rounds=\u001b[32m10\u001b[39m,\n\u001b[32m    385\u001b[39m     agent=\u001b[33m'\u001b[39m\u001b[33mresearcher\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    386\u001b[39m     researcher_model=cmbagent_model,\n\u001b[32m    387\u001b[39m )\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     total_time += \u001b[43mextract_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_answer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/p/stage/cmbagent_benchmark/python/evaluation/evaluation.py:313\u001b[39m, in \u001b[36mextract_time\u001b[39m\u001b[34m(model_answer)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_time\u001b[39m(model_answer: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     match = \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTask took ([\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43md.]+) seconds\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_answer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[32m    315\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(match.group(\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/re/__init__.py:177\u001b[39m, in \u001b[36msearch\u001b[39m\u001b[34m(pattern, string, flags)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch\u001b[39m(pattern, string, flags=\u001b[32m0\u001b[39m):\n\u001b[32m    175\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[32m    176\u001b[39m \u001b[33;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: expected string or bytes-like object, got 'dict'"
     ]
    }
   ],
   "source": [
    "info = run_benchmark(\n",
    "    problem_json=\"/mnt/p/stage/cmbagent_benchmark/data/clean/easy_custom_samples.json\",\n",
    "    problem_dir=\"/mnt/p/stage/cmbagent_benchmark/data/clean/easy_tests\",\n",
    "    eval_cmbagent=True,\n",
    "    cmbagent_model=\"claude-3-7-sonnet-latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e39906-1c7d-477a-b732-ef6129cc23c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43minfo\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'info' is not defined"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67557c-044a-40a2-afae-2b0a1079bf81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cmbagent_env)",
   "language": "python",
   "name": "cmbagent_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
